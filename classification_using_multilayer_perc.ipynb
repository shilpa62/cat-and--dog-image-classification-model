{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification model using multilayer perceptron\n",
    "\n",
    "- classify images (either dog or cat)\n",
    "- dataset consist of 10000 images of dogs and cat\n",
    "- cat are labelled as 1.0 and dogs are labelled as 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import cv2\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from numpy import save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 30000) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#reading and resizing images\n",
    "path = r'C:\\Users\\shilp\\OneDrive\\Desktop\\data4'\n",
    "images  = []\n",
    "labels=[]\n",
    "count=0\n",
    "for file in listdir(path):\n",
    "    output = 0.0\n",
    "    if file.startswith('cat'):\n",
    "        output = 1.0\n",
    "    for file1 in listdir(path+\"\\\\\"+file):\n",
    "        photo = cv2.imread(path +\"\\\\\"+ file+\"\\\\\"+file1)\n",
    "        if photo is not None:\n",
    "            photo = cv2.resize(photo, (100,100)).flatten()\n",
    "            images.append(photo)\n",
    "            labels.append(output)\n",
    "\n",
    "        else:\n",
    "            print(file1,file)\n",
    "            print(\"image not loaded\")\n",
    "       \n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "print(images.shape, labels.shape)\n",
    "\n",
    "save('dogs_vs_cats_photos.npy', images )\n",
    "save('dogs_vs_cats_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img',images[8])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=pd.DataFrame({\"labels\":labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5000\n",
       "1.0    5000\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing data into train and test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test, y_train,y_test=train_test_split(images, labels,test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating model\n",
    "model = Sequential()\n",
    "model.add(Dense(768,input_dim=30000,activation=\"relu\"))\n",
    "model.add(Dense(384, activation=\"relu\" ))\n",
    "model.add(Dense(1, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shilp\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shilp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shilp\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\shilp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shilp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shilp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\shilp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shilp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shilp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shilp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shilp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "6400/6400 [==============================] - 34s 5ms/step - loss: 7.9936 - acc: 0.4986 - val_loss: 7.8616 - val_acc: 0.5069\n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 29s 4ms/step - loss: 7.9936 - acc: 0.4986 - val_loss: 7.8616 - val_acc: 0.5069\n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 30s 5ms/step - loss: 7.9936 - acc: 0.4986 - val_loss: 7.8616 - val_acc: 0.5069\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 30s 5ms/step - loss: 7.9936 - acc: 0.4986 - val_loss: 7.8616 - val_acc: 0.5069\n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 30s 5ms/step - loss: 7.9936 - acc: 0.4986 - val_loss: 7.8616 - val_acc: 0.5069\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 29s 5ms/step - loss: 7.9936 - acc: 0.4986 - val_loss: 7.8616 - val_acc: 0.5069\n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 30s 5ms/step - loss: 7.9936 - acc: 0.4986 - val_loss: 7.8616 - val_acc: 0.5069\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 29s 5ms/step - loss: 7.9936 - acc: 0.4986 - val_loss: 7.8616 - val_acc: 0.5069\n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 29s 5ms/step - loss: 7.9936 - acc: 0.4986 - val_loss: 7.8616 - val_acc: 0.5069\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 30s 5ms/step - loss: 7.9936 - acc: 0.4986 - val_loss: 7.8616 - val_acc: 0.5069\n"
     ]
    }
   ],
   "source": [
    "#sgd = SGD(lr=0.01,momentum=0.9)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "\n",
    "#history = model.fit(x_train,y_train, epochs=50, batch_size=128,verbose=1,validation_data=0.2)\n",
    "history=model.fit(x_train,y_train,shuffle=True, epochs=10,batch_size=128,validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 3s 1ms/step\n",
      "LOSS:\n",
      "7.987134727478027\n",
      "precision:\n",
      "0.499\n"
     ]
    }
   ],
   "source": [
    "#to check precision\n",
    "score = model.evaluate(x_test,y_test)\n",
    "print(\"LOSS:\")\n",
    "print(score[0])\n",
    "print(\"precision:\")         \n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model accuracy is 49% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
